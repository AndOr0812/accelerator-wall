CNN Architecture,Title ,Conference,FPGA ,CMOS Technology[nm], Frequency[MHz], Total Transistors (computed), LUT util. (%), DSP util. (%), BRAM util. (%), Precision, Power[W], Throughput[GOPS], Nominal Throughput[GOPS*precision], Energy Efficiency[GOP/J] , Nominal Energy Efficiency[GOP*precision/J], CMOS Potential Throughput, CMOS Potential Energy Efficiency
AlexNet, Automated Systolic Array Architecture Synthesis for High Throughput CNN Inference on FPGAs, DAC2017, GX1150,20,239.62,8226206000,82,84.98023715,86.98857353, 32b float, None,360.4,11532.8, None, None,1.97E+12,153854574
AlexNet, Efficient FPGA acceleration of Convolutional Neural Networks using logical-3D compute array, DATE2016, VX485T,28,100,1215516393,9.222661397,96.25,52.71000001, 16b fixed, None,80.78,1292.48, None, None,1.22E+11,45977011.49
AlexNet, Optimizing FPGA-based Accelerator Design for Deep Convolutional Neural Networks, FPGA2015, VX485T,28,100,2141329920,61.26482213,80,49.70873786, 32b float,18.61,61.62,1971.84,3.311123052,105.9559377,2.14E+11,45977011.49
AlexNet, Throughput-Optimized OpenCL-based FPGA Accelerator for Large-Scale Convolutional Neural Networks, FPGA2016, GSD8,28,120,3069070464,43.72990354,38.30871116,60.2, 16b fixed,25.8,72.4,1158.4,2.80620155,44.89922481,3.68E+11,54945054.95
AlexNet, Scalable and modularized RTL compilation of Convolutional Neural Networks onto FPGA, FPGA2016$\ast$, GXA7,28,200,2871429120,34.82014388,100,61.83093105, 16b fixed, None,282.67,4522.72, None, None,5.74E+11,90090090.09
AlexNet, An OpenCL Deep Learning Accelerator on Arria 10, FPGA2017$\ast$, GX1150,20,303,6374734048,58,97.23320158,84.33615923, 16b float,45,1382,22112,30.71111111,491.3777778,1.93E+12,192994368.1
AlexNet, Improving the Performance of OpenCL-based FPGA Accelerator for Convolutional Neural Network, FPGA2017$\dagger$, GX1150,20,370,3936273600,37.109375,86.95652174,46.07445632, 32b float,41.73493976,866,27712,20.75,664,1.46E+12,233695034.3
AlexNet, A Framework for Generating High Throughput CNN Implementations on FPGAs, FPGA2018$\dagger$, GXA7,28,200,3240993280,47,100,53.64238411, 16b fixed, None,780.6,12489.6, None, None,6.48E+11,90090090.09
AlexNet, A High Performance FPGA-based Accelerator for Large-Scale Convolutional Neural Networks, FPL2016, VX690T,28,150,3351573760,63.25023084,59.55555556,65.06802722, 16b fixed,30.2,566,9056,18.74172185,299.8675497,5.03E+11,68259385.67
AlexNet,Maximizing CNN Accelerator Efficiency Through Resource Partitioning, ISCA2017, VX690T,28,150,2852818040,54.68605725,88.25,48.84353742, 32b float,10.2,113.92,3645.44,11.16862745,357.3960784,4.28E+11,68259385.67
AlexNet, Maximizing CNN Accelerator Efficiency Through Resource Partitioning, ISCA2017, VX485T,28,150,1943265000,58.20158103,87.25,39.41747573, 32b float,7.6,73.77,2360.64,9.706578947,310.6105263,2.91E+11,68259385.67
VGG-16, Automated Systolic Array Architecture Synthesis for High Throughput CNN Inference on FPGAs, DAC2017, GX1150,20,221.65,6716215072,60.12228261,88.2740448,93.03943973, 32b float, None,460.5,14736, None, None,1.49E+12,142642317.5
VGG-16, Automated Systolic Array Architecture Synthesis for High Throughput CNN Inference on FPGAs, DAC2017, GX1150,20,231.85,5538517536,53.15896739,98.81422925,63.03280501, 16b fixed, None,1171.3,18740.8, None, None,1.28E+12,149012829.4
VGG-16,Going Deeper with Embedded FPGA Platform for Convolutional Neural Network, FPGA2016$\dagger$, XC7Z045,28,150,1973437600,83.71454712,86.66666667,91.33537207, 16b fixed,9.63,137,2192,14.22637591,227.6220145,2.96E+11,68259385.67
VGG-16, Optimizing Loop Operation and Dataflow in FPGA Acceleration of Deep Convolutional Neural Networks, FPGA2017, GX1150,20,150,3787430160,27.34375,100,71.71396978, 16b fixed,21.2,645.25,10324,30.43632075,486.9811321,5.68E+11,97421575.63
VGG-16, Towards a Uniform Template-based Architecture for Accelerating 2D and 3D CNNs on FPGA, FPGA2018, XCVU440,20,200,3681608960,8.251346272,47.77777778,59.84126984, 16b fixed,26,821,13136,31.57692308,505.2307692,7.36E+11,129065565.3
VGG-16, An automatic RTL compiler for high-throughput FPGA implementation of diverse deep convolutional neural networks, FPL2017, GXA7,28,200,4541153280,61.03597122,100,85.78106739, 16b fixed, None,352.64,5642.24, None, None,9.08E+11,90090090.09
VGG-16, An automatic RTL compiler for high-throughput FPGA implementation of diverse deep convolutional neural networks, FPL2017, GX1150,20,150,3641274640,22.36752717,100,82.01253225, 16b fixed, None,720.15,11522.4, None, None,5.46E+11,97421575.63
VGG-16, Caffeine: Towards uniformed representation and acceleration for deep convolutional neural networks, ICCAD2016, VX690T,28,150,3042956280,67.62898199,78.69444444,42.44897959, 16b fixed,26,354,5664,13.61538462,217.8461538,4.56E+11,68259385.67
VGG-16,Throughput-Optimal OpenCLbased FPGA Accelerator for Large-Scale Convolutional Neural Networks,ISPLED2016, GSD8,28,120,4523117960,84.24437299,37.03515028,52.734375, 16b fixed,25.8,117.8,1884.8,4.565891473,73.05426357,5.43E+11,54945054.95
